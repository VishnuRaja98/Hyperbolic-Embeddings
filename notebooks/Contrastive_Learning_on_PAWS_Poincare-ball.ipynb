{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d6d2f2c-8f38-45b2-ab1b-87150b19aa57",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cronus_data/vraja/dysarthria/lib/python3.11/site-packages/transformers/utils/hub.py:105: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import csv\n",
    "import os\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.stats import spearmanr\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from tqdm import tqdm\n",
    "import geoopt\n",
    "from datetime import datetime\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "torch.manual_seed(42)\n",
    "base_path = \"paws\"\n",
    "\n",
    "# Set GPU device\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"  # Change as needed\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# -----------------------------\n",
    "# 1. Dataset Class for Binary Paraphrase Data\n",
    "# -----------------------------\n",
    "\n",
    "class BinaryParaphraseDataset(Dataset):\n",
    "    def __init__(self, file_path, tokenizer, max_length=128):\n",
    "        self.data = self.read_file(file_path)\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def read_file(self, file_path):\n",
    "        data = []\n",
    "        problem_rows = 0\n",
    "    \n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            csv_reader = csv.reader(file, delimiter='\\t', quotechar=None)\n",
    "            headers = next(csv_reader, None)  # Read and skip the header row\n",
    "    \n",
    "            for row in csv_reader:\n",
    "                if len(row) == 4:\n",
    "                    sentence1, sentence2, label_str = row[1], row[2], row[3] \n",
    "                    try:\n",
    "                        # Ensure label is either 0 or 1 (binary)\n",
    "                        label = int(float(label_str))  # Support for both integer and float formats\n",
    "                        if label not in [0, 1]:\n",
    "                            # Normalize any other value to binary (0 or 1)\n",
    "                            # Typically, values > 0 could be considered paraphrases\n",
    "                            label = 1 if label > 0 else 0\n",
    "                        data.append((sentence1.strip(), sentence2.strip(), label))\n",
    "                    except:\n",
    "                        continue\n",
    "                else:\n",
    "                    problem_rows += 1\n",
    "    \n",
    "        print(\"!!!!!!total problem rows = \", problem_rows)\n",
    "        return data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sentence1, sentence2, label = self.data[idx]\n",
    "        \n",
    "        # Tokenize both sentences\n",
    "        input1 = self.tokenizer(\n",
    "            sentence1, \n",
    "            padding='max_length', \n",
    "            truncation=True, \n",
    "            max_length=self.max_length, \n",
    "            return_tensors=\"pt\",\n",
    "            return_token_type_ids=False\n",
    "        )\n",
    "        \n",
    "        input2 = self.tokenizer(\n",
    "            sentence2, \n",
    "            padding='max_length', \n",
    "            truncation=True, \n",
    "            max_length=self.max_length, \n",
    "            return_tensors=\"pt\",\n",
    "            return_token_type_ids=False\n",
    "        )\n",
    "        \n",
    "        # Remove batch dimension\n",
    "        input1 = {k: v.squeeze(0) for k, v in input1.items()}\n",
    "        input2 = {k: v.squeeze(0) for k, v in input2.items()}\n",
    "        \n",
    "        return {\n",
    "            'input1': input1,\n",
    "            'input2': input2,\n",
    "            'label': torch.tensor(label, dtype=torch.float32)\n",
    "        }\n",
    "\n",
    "# -----------------------------\n",
    "# 2. Hyperbolic Model\n",
    "# -----------------------------    \n",
    "class HyperbolicMapper(nn.Module):\n",
    "    def __init__(self, sbert_model_name='sentence-transformers/all-MiniLM-L6-v2', output_dim=32):\n",
    "        super(HyperbolicMapper, self).__init__()\n",
    "        # Frozen SBERT\n",
    "        self.sbert = AutoModel.from_pretrained(sbert_model_name)\n",
    "        for param in self.sbert.parameters():\n",
    "            param.requires_grad = False\n",
    "        \n",
    "        sbert_hidden_dim = self.sbert.config.hidden_size\n",
    "        self.curvature = nn.Parameter(torch.tensor(1.0))\n",
    "        self.temperature = nn.Parameter(torch.tensor(1.0))\n",
    "        \n",
    "        # Projection layer\n",
    "        self.projection = nn.Sequential(\n",
    "            nn.Linear(sbert_hidden_dim, output_dim))\n",
    "        \n",
    "        print(\"Initialized hyperbolic model with output dimension:\", output_dim)\n",
    "\n",
    "    def poincare_project(self, x):\n",
    "        \"\"\"Project vectors onto the Poincaré ball\"\"\"\n",
    "        x = x / self.temperature\n",
    "        norm = torch.norm(x, p=2, dim=-1, keepdim=True)\n",
    "        scale = (1 - 1e-5) / torch.clamp(norm * torch.sqrt(self.curvature), min=1e-5)\n",
    "        return x * scale\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        with torch.no_grad():\n",
    "            sbert_output = self.sbert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            cls_embedding = sbert_output.last_hidden_state[:, 0]\n",
    "        \n",
    "        projected = self.projection(cls_embedding)\n",
    "        return self.poincare_project(projected)\n",
    "\n",
    "# -----------------------------\n",
    "# 3. Hyperbolic Distance Functions\n",
    "# -----------------------------\n",
    "\n",
    "def poincare_distance(x, y, curvature=1.0, eps=1e-5):\n",
    "    \"\"\"Compute Poincaré distance between vectors\"\"\"\n",
    "    sqrt_c = torch.sqrt(curvature + eps)\n",
    "    \n",
    "    # Handle different dimensions\n",
    "    if x.dim() == 2 and y.dim() == 2:\n",
    "        # Both are batch of vectors\n",
    "        # Compute norms\n",
    "        x_norm = torch.norm(x, p=2, dim=-1, keepdim=True) * sqrt_c\n",
    "        y_norm = torch.norm(y, p=2, dim=-1, keepdim=True) * sqrt_c\n",
    "        \n",
    "        # Compute pairwise distance\n",
    "        pairwise_norm = torch.norm(x - y, p=2, dim=-1, keepdim=True) * sqrt_c\n",
    "        \n",
    "        # Hyperbolic distance calculation\n",
    "        denominator = (1 - curvature * x_norm**2) * (1 - curvature * y_norm**2)\n",
    "        inside = 1 + 2 * curvature * pairwise_norm**2 / (denominator.clamp(min=eps))\n",
    "        return torch.acosh(torch.clamp(inside, min=1+eps)).squeeze(-1) / (sqrt_c + eps)\n",
    "    else:\n",
    "        raise ValueError(f\"Incompatible shapes: x {x.shape}, y {y.shape}\")\n",
    "\n",
    "\n",
    "def hyperbolic_contrastive_loss(dist, labels, pos_margin=0.5, neg_margin=2.0, pos_weight=1.0, neg_weight=1.0):\n",
    "    # For positive pairs: penalize if distance > pos_margin\n",
    "    # For negative pairs: penalize if distance < neg_margin\n",
    "    pos_loss = torch.clamp(dist - pos_margin, min=0.0) ** 2\n",
    "    neg_loss = torch.clamp(neg_margin - dist, min=0.0) ** 2\n",
    "    loss = pos_weight * labels * pos_loss + neg_weight * (1 - labels) * neg_loss\n",
    "    return loss.mean()\n",
    "\n",
    "# -----------------------------\n",
    "# 4. Training Functions\n",
    "# -----------------------------\n",
    "\n",
    "def train_one_epoch(train_loader, model, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    total_samples = 0\n",
    "    \n",
    "    # Initialize progress bar\n",
    "    prog_bar = tqdm(train_loader, desc=\"Training\", leave=False)\n",
    "    \n",
    "    for batch in prog_bar:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Get embeddings for both sentences\n",
    "        input1 = {k: v.to(device) for k, v in batch['input1'].items()}\n",
    "        input2 = {k: v.to(device) for k, v in batch['input2'].items()}\n",
    "        \n",
    "        # Forward pass\n",
    "        embeds1 = model(**input1)\n",
    "        embeds2 = model(**input2)\n",
    "        \n",
    "        # Compute hyperbolic distance\n",
    "        distances = poincare_distance(embeds1, embeds2, curvature=model.curvature)\n",
    "        \n",
    "        # Get labels\n",
    "        labels = batch['label'].to(device)\n",
    "        \n",
    "        # Compute loss\n",
    "        loss = hyperbolic_contrastive_loss(distances, labels)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Update tracking\n",
    "        batch_size = labels.size(0)\n",
    "        total_loss += loss.item() * batch_size\n",
    "        total_samples += batch_size\n",
    "        \n",
    "        # Update progress bar\n",
    "        prog_bar.set_postfix({\n",
    "            'loss': loss.item(),\n",
    "            'curv': model.curvature.item(),\n",
    "            'temp': model.temperature.item()\n",
    "        })\n",
    "    \n",
    "    # Return average loss\n",
    "    return total_loss / total_samples if total_samples > 0 else 0\n",
    "\n",
    "def validate(loader, model, device, threshold=0.5):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    total_loss = 0\n",
    "    \n",
    "    # Use tqdm for progress tracking\n",
    "    prog_bar = tqdm(loader, desc=\"Validation\", leave=False)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in prog_bar:\n",
    "            # Get embeddings for both sentences\n",
    "            input1 = {k: v.to(device) for k, v in batch['input1'].items()}\n",
    "            input2 = {k: v.to(device) for k, v in batch['input2'].items()}\n",
    "            \n",
    "            # Forward pass\n",
    "            embeds1 = model(**input1)\n",
    "            embeds2 = model(**input2)\n",
    "            \n",
    "            # Compute hyperbolic distance\n",
    "            distances = poincare_distance(embeds1, embeds2, curvature=model.curvature)\n",
    "            \n",
    "            # Get labels\n",
    "            labels = batch['label'].to(device)\n",
    "            \n",
    "            # Compute loss\n",
    "            loss = hyperbolic_contrastive_loss(distances, labels)\n",
    "            total_loss += loss.item() * labels.size(0)\n",
    "            \n",
    "            # Compute binary predictions using distance threshold\n",
    "            # If distance < threshold, predict paraphrase (1), else non-paraphrase (0)\n",
    "            predictions = (distances < threshold).float()\n",
    "            \n",
    "            # Store predictions and labels for metrics\n",
    "            all_preds.extend(predictions.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            \n",
    "            # Update progress bar\n",
    "            prog_bar.set_postfix({'val_loss': loss.item()})\n",
    "    \n",
    "    # Calculate metrics\n",
    "    all_preds = np.array(all_preds).astype(int)\n",
    "    all_labels = np.array(all_labels).astype(int)\n",
    "    \n",
    "    # Calculate accuracy manually to avoid potential issues\n",
    "    accuracy = np.mean(all_preds == all_labels)\n",
    "    \n",
    "    # For precision, recall, and F1, handle potential errors\n",
    "    try:\n",
    "        # Try with average='binary' first\n",
    "        precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "            all_labels, all_preds, average='binary', zero_division=0\n",
    "        )\n",
    "    except ValueError:\n",
    "        # Fall back to macro averaging if we get an error\n",
    "        precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "            all_labels, all_preds, average='macro', zero_division=0\n",
    "        )\n",
    "    \n",
    "    # Calculate average loss\n",
    "    avg_loss = total_loss / len(all_labels) if len(all_labels) > 0 else 0\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "        'loss': avg_loss\n",
    "    }\n",
    "\n",
    "# -----------------------------\n",
    "# 5. Data Loading and Training\n",
    "# -----------------------------\n",
    "\n",
    "def collate_fn(batch):\n",
    "    \"\"\"Collate function for DataLoader\"\"\"\n",
    "    return {\n",
    "        'input1': {\n",
    "            k: torch.stack([item['input1'][k] for item in batch])\n",
    "            for k in batch[0]['input1']\n",
    "        },\n",
    "        'input2': {\n",
    "            k: torch.stack([item['input2'][k] for item in batch])\n",
    "            for k in batch[0]['input2']\n",
    "        },\n",
    "        'label': torch.stack([item['label'] for item in batch])\n",
    "    }\n",
    "\n",
    "def train_model(model, train_loader, val_loader, test_loader, label, optimizer, num_epochs=20):\n",
    "    \"\"\"Main training function\"\"\"\n",
    "    best_val_f1 = float('-inf')\n",
    "    log_data = {\n",
    "        'training_start': datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "        'config': {\n",
    "            'model': label,\n",
    "            'num_epochs': num_epochs,\n",
    "            'optimizer': str(optimizer.__class__.__name__),\n",
    "            'device': str(device)\n",
    "        },\n",
    "        'epochs': []\n",
    "    }\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # Initialize logging\n",
    "        epoch_start = datetime.now()\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "    \n",
    "        # Train for one epoch\n",
    "        train_loss = train_one_epoch(train_loader, model, optimizer, device)\n",
    "        \n",
    "        # Validate\n",
    "        val_metrics = validate(val_loader, model, device)\n",
    "\n",
    "        # Track epoch data\n",
    "        epoch_log = {\n",
    "            'epoch': epoch + 1,\n",
    "            'train_loss': float(train_loss),\n",
    "            'val_loss': float(val_metrics['loss']),\n",
    "            'val_accuracy': float(val_metrics['accuracy']),\n",
    "            'val_precision': float(val_metrics['precision']),\n",
    "            'val_recall': float(val_metrics['recall']),\n",
    "            'val_f1': float(val_metrics['f1']),\n",
    "            'duration_seconds': (datetime.now() - epoch_start).total_seconds(),\n",
    "            'is_best': False\n",
    "        }\n",
    "        \n",
    "        # Print metrics\n",
    "        print(f\"  Train Loss: {train_loss:.4f}\")\n",
    "        print(f\"  Val Loss: {val_metrics['loss']:.4f}\")\n",
    "        print(f\"  Val Accuracy: {val_metrics['accuracy']:.4f}\")\n",
    "        print(f\"  Val F1: {val_metrics['f1']:.4f}\")\n",
    "    \n",
    "        # Save if best model\n",
    "        if val_metrics['f1'] > best_val_f1:\n",
    "            best_val_f1 = val_metrics['f1']\n",
    "            torch.save(model.state_dict(), f'saved_models3/{label}.pt')\n",
    "            epoch_log['is_best'] = True\n",
    "            print(f\"  -> Best model saved (val_f1 improved to {best_val_f1:.4f})\")\n",
    "\n",
    "        log_data['epochs'].append(epoch_log)\n",
    "        \n",
    "        # Save logs after each epoch (in case of crash)\n",
    "        os.makedirs('model_logs3', exist_ok=True)\n",
    "        with open(f'model_logs3/{label}_logs.json', 'w') as f:\n",
    "            json.dump(log_data, f, indent=2)\n",
    "    \n",
    "    # Final evaluation on test set\n",
    "    print(\"Evaluating on test set...\")\n",
    "    test_metrics = validate(test_loader, model, device)\n",
    "    log_data['test_metrics'] = {\n",
    "        'accuracy': float(test_metrics['accuracy']),\n",
    "        'precision': float(test_metrics['precision']),\n",
    "        'recall': float(test_metrics['recall']),\n",
    "        'f1': float(test_metrics['f1']),\n",
    "        'loss': float(test_metrics['loss'])\n",
    "    }\n",
    "    \n",
    "    # Print test metrics\n",
    "    print(f\"Test Results:\")\n",
    "    print(f\"  Accuracy: {test_metrics['accuracy']:.4f}\")\n",
    "    print(f\"  Precision: {test_metrics['precision']:.4f}\")\n",
    "    print(f\"  Recall: {test_metrics['recall']:.4f}\")\n",
    "    print(f\"  F1 Score: {test_metrics['f1']:.4f}\")\n",
    "    \n",
    "    # Add final metadata\n",
    "    log_data['training_end'] = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    log_data['best_val_f1'] = float(best_val_f1)\n",
    "    \n",
    "    # Final save\n",
    "    with open(f'model_logs3/{label}_logs.json', 'w') as f:\n",
    "        json.dump(log_data, f, indent=2)\n",
    "    \n",
    "    return log_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab6a33ac-f8ce-45ca-9fd5-27e00271b2f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading datasets from:\n",
      "  Train: paws/train.tsv\n",
      " Dev: paws/dev.tsv\n",
      "  Test: paws/test.tsv\n",
      "!!!!!!total problem rows =  0\n",
      "!!!!!!total problem rows =  0\n",
      "!!!!!!total problem rows =  0\n",
      "Train dataset label distribution: {0: 27572, 1: 21829}\n",
      "Val dataset label distribution: {0: 4461, 1: 3539}\n",
      "Test dataset label distribution: {0: 4464, 1: 3536}\n",
      "Train size: 49401\n",
      "Val size: 8000\n",
      "Test size: 8000\n",
      "\n",
      "Training model with dimension 384\n",
      "Initialized hyperbolic model with output dimension: 384\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss: 7.9516\n",
      "  Val Loss: 1.3423\n",
      "  Val Accuracy: 0.5440\n",
      "  Val F1: 0.6026\n",
      "  -> Best model saved (val_f1 improved to 0.6026)\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss: 0.5977\n",
      "  Val Loss: 1.5389\n",
      "  Val Accuracy: 0.4944\n",
      "  Val F1: 0.6066\n",
      "  -> Best model saved (val_f1 improved to 0.6066)\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss: 0.5764\n",
      "  Val Loss: 1.5179\n",
      "  Val Accuracy: 0.4999\n",
      "  Val F1: 0.6074\n",
      "  -> Best model saved (val_f1 improved to 0.6074)\n",
      "Epoch 4/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss: 0.5748\n",
      "  Val Loss: 1.4980\n",
      "  Val Accuracy: 0.5058\n",
      "  Val F1: 0.6091\n",
      "  -> Best model saved (val_f1 improved to 0.6091)\n",
      "Epoch 5/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss: 0.5717\n",
      "  Val Loss: 1.4955\n",
      "  Val Accuracy: 0.5065\n",
      "  Val F1: 0.6092\n",
      "  -> Best model saved (val_f1 improved to 0.6092)\n",
      "Epoch 6/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss: 0.5730\n",
      "  Val Loss: 1.4796\n",
      "  Val Accuracy: 0.5132\n",
      "  Val F1: 0.6117\n",
      "  -> Best model saved (val_f1 improved to 0.6117)\n",
      "Epoch 7/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss: 0.5705\n",
      "  Val Loss: 1.4696\n",
      "  Val Accuracy: 0.5165\n",
      "  Val F1: 0.6122\n",
      "  -> Best model saved (val_f1 improved to 0.6122)\n",
      "Epoch 8/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss: 0.5691\n",
      "  Val Loss: 1.4614\n",
      "  Val Accuracy: 0.5150\n",
      "  Val F1: 0.6101\n",
      "Epoch 9/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss: 0.5696\n",
      "  Val Loss: 1.4435\n",
      "  Val Accuracy: 0.5201\n",
      "  Val F1: 0.6106\n",
      "Epoch 10/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss: 0.5685\n",
      "  Val Loss: 1.4486\n",
      "  Val Accuracy: 0.5205\n",
      "  Val F1: 0.6123\n",
      "  -> Best model saved (val_f1 improved to 0.6123)\n",
      "Epoch 11/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss: 0.5685\n",
      "  Val Loss: 1.4536\n",
      "  Val Accuracy: 0.5191\n",
      "  Val F1: 0.6117\n",
      "Epoch 12/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss: 0.5683\n",
      "  Val Loss: 1.4396\n",
      "  Val Accuracy: 0.5232\n",
      "  Val F1: 0.6118\n",
      "Epoch 13/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss: 0.5671\n",
      "  Val Loss: 1.4302\n",
      "  Val Accuracy: 0.5274\n",
      "  Val F1: 0.6130\n",
      "  -> Best model saved (val_f1 improved to 0.6130)\n",
      "Epoch 14/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss: 0.5669\n",
      "  Val Loss: 1.4304\n",
      "  Val Accuracy: 0.5275\n",
      "  Val F1: 0.6129\n",
      "Epoch 15/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss: 0.5655\n",
      "  Val Loss: 1.4277\n",
      "  Val Accuracy: 0.5280\n",
      "  Val F1: 0.6126\n",
      "Epoch 16/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss: 0.5665\n",
      "  Val Loss: 1.4204\n",
      "  Val Accuracy: 0.5301\n",
      "  Val F1: 0.6128\n",
      "Epoch 17/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss: 0.5654\n",
      "  Val Loss: 1.4407\n",
      "  Val Accuracy: 0.5228\n",
      "  Val F1: 0.6117\n",
      "Epoch 18/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss: 0.5650\n",
      "  Val Loss: 1.4369\n",
      "  Val Accuracy: 0.5241\n",
      "  Val F1: 0.6122\n",
      "Epoch 19/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss: 0.5662\n",
      "  Val Loss: 1.4265\n",
      "  Val Accuracy: 0.5264\n",
      "  Val F1: 0.6120\n",
      "Epoch 20/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss: 0.5638\n",
      "  Val Loss: 1.4188\n",
      "  Val Accuracy: 0.5282\n",
      "  Val F1: 0.6116\n",
      "Evaluating on test set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Results:\n",
      "  Accuracy: 0.5354\n",
      "  Precision: 0.4852\n",
      "  Recall: 0.8405\n",
      "  F1 Score: 0.6153\n",
      "\n",
      "Training model with dimension 192\n",
      "Initialized hyperbolic model with output dimension: 192\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss: 8.2299\n",
      "  Val Loss: 1.3327\n",
      "  Val Accuracy: 0.5507\n",
      "  Val F1: 0.6055\n",
      "  -> Best model saved (val_f1 improved to 0.6055)\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss: 0.6035\n",
      "  Val Loss: 1.5435\n",
      "  Val Accuracy: 0.4923\n",
      "  Val F1: 0.6057\n",
      "  -> Best model saved (val_f1 improved to 0.6057)\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss: 0.5794\n",
      "  Val Loss: 1.5213\n",
      "  Val Accuracy: 0.4996\n",
      "  Val F1: 0.6090\n",
      "  -> Best model saved (val_f1 improved to 0.6090)\n",
      "Epoch 4/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss: 0.5763\n",
      "  Val Loss: 1.5009\n",
      "  Val Accuracy: 0.5040\n",
      "  Val F1: 0.6088\n",
      "Epoch 5/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss: 0.5740\n",
      "  Val Loss: 1.4848\n",
      "  Val Accuracy: 0.5081\n",
      "  Val F1: 0.6097\n",
      "  -> Best model saved (val_f1 improved to 0.6097)\n",
      "Epoch 6/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss: 0.5736\n",
      "  Val Loss: 1.4764\n",
      "  Val Accuracy: 0.5135\n",
      "  Val F1: 0.6116\n",
      "  -> Best model saved (val_f1 improved to 0.6116)\n",
      "Epoch 7/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss: 0.5710\n",
      "  Val Loss: 1.4594\n",
      "  Val Accuracy: 0.5170\n",
      "  Val F1: 0.6112\n",
      "Epoch 8/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss: 0.5716\n",
      "  Val Loss: 1.4518\n",
      "  Val Accuracy: 0.5196\n",
      "  Val F1: 0.6121\n",
      "  -> Best model saved (val_f1 improved to 0.6121)\n",
      "Epoch 9/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss: 0.5708\n",
      "  Val Loss: 1.4523\n",
      "  Val Accuracy: 0.5191\n",
      "  Val F1: 0.6122\n",
      "  -> Best model saved (val_f1 improved to 0.6122)\n",
      "Epoch 10/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss: 0.5702\n",
      "  Val Loss: 1.4525\n",
      "  Val Accuracy: 0.5214\n",
      "  Val F1: 0.6134\n",
      "  -> Best model saved (val_f1 improved to 0.6134)\n",
      "Epoch 11/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss: 0.5697\n",
      "  Val Loss: 1.4233\n",
      "  Val Accuracy: 0.5281\n",
      "  Val F1: 0.6132\n",
      "Epoch 12/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss: 0.5671\n",
      "  Val Loss: 1.4434\n",
      "  Val Accuracy: 0.5221\n",
      "  Val F1: 0.6125\n",
      "Epoch 13/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss: 0.5679\n",
      "  Val Loss: 1.4324\n",
      "  Val Accuracy: 0.5255\n",
      "  Val F1: 0.6128\n",
      "Epoch 14/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss: 0.5678\n",
      "  Val Loss: 1.4334\n",
      "  Val Accuracy: 0.5236\n",
      "  Val F1: 0.6115\n",
      "Epoch 15/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss: 0.5672\n",
      "  Val Loss: 1.4377\n",
      "  Val Accuracy: 0.5240\n",
      "  Val F1: 0.6120\n",
      "Epoch 16/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss: 0.5660\n",
      "  Val Loss: 1.4262\n",
      "  Val Accuracy: 0.5268\n",
      "  Val F1: 0.6122\n",
      "Epoch 17/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss: 0.5658\n",
      "  Val Loss: 1.4297\n",
      "  Val Accuracy: 0.5276\n",
      "  Val F1: 0.6137\n",
      "  -> Best model saved (val_f1 improved to 0.6137)\n",
      "Epoch 18/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss: 0.5662\n",
      "  Val Loss: 1.4267\n",
      "  Val Accuracy: 0.5279\n",
      "  Val F1: 0.6131\n",
      "Epoch 19/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss: 0.5652\n",
      "  Val Loss: 1.4292\n",
      "  Val Accuracy: 0.5281\n",
      "  Val F1: 0.6137\n",
      "  -> Best model saved (val_f1 improved to 0.6137)\n",
      "Epoch 20/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss: 0.5651\n",
      "  Val Loss: 1.4137\n",
      "  Val Accuracy: 0.5331\n",
      "  Val F1: 0.6142\n",
      "  -> Best model saved (val_f1 improved to 0.6142)\n",
      "Evaluating on test set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Results:\n",
      "  Accuracy: 0.5386\n",
      "  Precision: 0.4873\n",
      "  Recall: 0.8385\n",
      "  F1 Score: 0.6164\n",
      "\n",
      "Results Summary:\n",
      "Dimension 384: F1=0.6153, Accuracy=0.5354\n",
      "Dimension 192: F1=0.6164, Accuracy=0.5386\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # Create directories if they don't exist\n",
    "    os.makedirs('saved_models3', exist_ok=True)\n",
    "    os.makedirs('model_logs3', exist_ok=True)\n",
    "    \n",
    "    # Initialize tokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/all-MiniLM-L6-v2')\n",
    "    \n",
    "    # Load datasets\n",
    "    # Update these paths to your dataset files\n",
    "    train_file = f'{base_path}/train.tsv'\n",
    "    val_file = f'{base_path}/dev.tsv'\n",
    "    test_file = f'{base_path}/test.tsv'\n",
    "    \n",
    "    print(f\"Loading datasets from:\\n  Train: {train_file}\\n Dev: {val_file}\\n  Test: {test_file}\")\n",
    "    \n",
    "    try:\n",
    "        train_dataset = BinaryParaphraseDataset(train_file, tokenizer)\n",
    "        val_dataset = BinaryParaphraseDataset(val_file, tokenizer)\n",
    "        test_dataset = BinaryParaphraseDataset(test_file, tokenizer)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading datasets: {e}\")\n",
    "        print(\"Please verify your file paths and format.\")\n",
    "        return\n",
    "    \n",
    "    # Count label distribution\n",
    "    train_labels = [data[-1] for data in train_dataset.data]\n",
    "    train_label_counts = {0: train_labels.count(0), 1: train_labels.count(1)}\n",
    "    print(f\"Train dataset label distribution: {train_label_counts}\")\n",
    "\n",
    "    # Count label distribution\n",
    "    val_labels = [data[-1] for data in val_dataset.data]\n",
    "    val_label_counts = {0: val_labels.count(0), 1: val_labels.count(1)}\n",
    "    print(f\"Val dataset label distribution: {val_label_counts}\")\n",
    "    \n",
    "    test_labels = [data[-1] for data in test_dataset.data]\n",
    "    test_label_counts = {0: test_labels.count(0), 1: test_labels.count(1)}\n",
    "    print(f\"Test dataset label distribution: {test_label_counts}\")\n",
    "    \n",
    "    if len(train_dataset) == 0 or len(test_dataset) == 0 or len(val_dataset) == 0:\n",
    "        print(\"Error: One or more datasets are empty. Please check your data files.\")\n",
    "        return\n",
    "    \n",
    "    \n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=32,\n",
    "        shuffle=True,\n",
    "        collate_fn=collate_fn\n",
    "    )\n",
    "    \n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=32,\n",
    "        shuffle=False,\n",
    "        collate_fn=collate_fn\n",
    "    )\n",
    "    \n",
    "    test_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=32,\n",
    "        shuffle=False,\n",
    "        collate_fn=collate_fn\n",
    "    )\n",
    "    \n",
    "    print(f\"Train size: {len(train_dataset)}\")\n",
    "    print(f\"Val size: {len(val_dataset)}\")\n",
    "    print(f\"Test size: {len(test_dataset)}\")\n",
    "    \n",
    "    # Train models with different dimensions\n",
    "    hyp_dims = [384, 192]\n",
    "    results = {}\n",
    "    \n",
    "    for dim in hyp_dims:\n",
    "        print(f\"\\nTraining model with dimension {dim}\")\n",
    "        # Initialize model\n",
    "        model = HyperbolicMapper(output_dim=dim).to(device)\n",
    "        \n",
    "        # Initialize optimizer\n",
    "        optimizer = geoopt.optim.RiemannianAdam(\n",
    "            model.parameters(),\n",
    "            lr=1e-4,\n",
    "            stabilize=1000  # Helps with numerical stability\n",
    "        )\n",
    "        \n",
    "        # Train model\n",
    "        try:\n",
    "            model_results = train_model(\n",
    "                model=model,\n",
    "                train_loader=train_loader,\n",
    "                val_loader=val_loader,\n",
    "                test_loader=test_loader,\n",
    "                label=f\"paws_hyp_{dim}\",\n",
    "                optimizer=optimizer,\n",
    "                num_epochs=20  # Adjust as needed\n",
    "            )\n",
    "            \n",
    "            # Store results\n",
    "            results[dim] = model_results\n",
    "        except Exception as e:\n",
    "            print(f\"Error training model with dimension {dim}: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "        \n",
    "        # Clear memory\n",
    "        del model\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    # Print summary of results\n",
    "    print(\"\\nResults Summary:\")\n",
    "    for dim, result in results.items():\n",
    "        test_f1 = result['test_metrics']['f1']\n",
    "        test_acc = result['test_metrics']['accuracy']\n",
    "        print(f\"Dimension {dim}: F1={test_f1:.4f}, Accuracy={test_acc:.4f}\")\n",
    "\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d45178-a532-4f75-97e5-1e6649ef637f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
